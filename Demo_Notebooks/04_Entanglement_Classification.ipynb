{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This code is part of a Qiskit project.\n",
        "#\n",
        "# (C) Copyright IBM 2025.\n",
        "#\n",
        "# This code is licensed under the Apache License, Version 2.0. You may\n",
        "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
        "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
        "#\n",
        "# Any modifications or derivative works of this code must retain this\n",
        "# copyright notice, and modified files need to carry a notice indicating\n",
        "# that they have been altered from the originals.\n",
        "\n",
        "\"\"\"\n",
        "Entanglement Concentration\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8M9smY9lgZFt"
      },
      "id": "8M9smY9lgZFt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is part of a Qiskit project.\n",
        "#\n",
        "# (C) Copyright IBM 2025.\n",
        "#\n",
        "# This code is licensed under the Apache License, Version 2.0. You may\n",
        "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
        "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
        "#\n",
        "# Any modifications or derivative works of this code must retain this\n",
        "# copyright notice, and modified files need to carry a notice indicating\n",
        "# that they have been altered from the originals.\n",
        "\n",
        "\"\"\"\n",
        "Test Entanglement Concentration\n",
        "\"\"\"\n",
        "\n",
        "from test import QiskitMachineLearningTestCase\n",
        "\n",
        "import unittest"
      ],
      "metadata": {
        "id": "Yv7Ft66kjL4g"
      },
      "id": "Yv7Ft66kjL4g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58NgCmZSgYFV"
      },
      "id": "58NgCmZSgYFV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f291447-df88-4f5c-be51-6273d598b470",
      "metadata": {
        "id": "4f291447-df88-4f5c-be51-6273d598b470"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from typing import List, Tuple\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.quantum_info import Statevector\n",
        "from qiskit.circuit import ParameterVector\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class HardwareEfficientDatasetGenerator:\n",
        "    def __init__(self, base_path: str = \"Hardware_Efficient\"):\n",
        "        self.base_path = base_path\n",
        "        self.supported_qubits = [3, 4, 8]\n",
        "        self.supported_depths_34 = list(range(1, 7))\n",
        "        self.supported_depths_8 = [5, 6]\n",
        "        self.supported_ce_34 = [0.05, 0.15, 0.25, 0.35]\n",
        "        self.supported_ce_8_6 = [0.10, 0.25]\n",
        "        self.supported_ce_8_5 = [0.15, 0.40, 0.45]\n",
        "\n",
        "    def validate_params(self, qubits: int, depth: int, goal_ce: float) -> bool:\n",
        "        # Validate inputs\n",
        "        if qubits not in self.supported_qubits:\n",
        "            raise ValueError(f\"Unsupported qubit count: {qubits}. Choose from {self.supported_qubits}\")\n",
        "\n",
        "        if (qubits == 8):\n",
        "            if depth not in self.supported_depths_8:\n",
        "                raise ValueError(f\"Unsupported depth: {depth}. Choose from {self.supported_depths_8}\")\n",
        "            if (depth == 6):\n",
        "                if goal_ce not in self.supported_ce_8_6:\n",
        "                    raise ValueError(f\"Unsupported CE value: {goal_ce}. Choose from {self.supported_ce_8_6}\")\n",
        "            else:\n",
        "                if goal_ce not in self.supported_ce_8_5:\n",
        "                    raise ValueError(f\"Unsupported CE value: {goal_ce}. Choose from {self.supported_ce_8_5}\")\n",
        "        else:\n",
        "            if depth not in self.supported_depths_34:\n",
        "                raise ValueError(f\"Unsupported depth: {depth}. Choose from {self.supported_depths_34}\")\n",
        "            if goal_ce not in self.supported_ce_34:\n",
        "                raise ValueError(f\"Unsupported CE value: {goal_ce}. Choose from {self.supported_ce_34}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _construct_filepath(self, qubits: int, depth: int, goal_ce: float) -> str:\n",
        "        \"\"\"\n",
        "        Construct the full file path based on parameters and directory structure.\n",
        "\n",
        "        Args:\n",
        "            qubits: Number of qubits (3 or 4)\n",
        "            depth: Circuit depth (1-6)\n",
        "            goal_ce: Target concentratable entanglement (0.05, 0.15, 0.25, 0.35, 0.5)\n",
        "\n",
        "        Returns:\n",
        "            Full path to .npy weights file\n",
        "        \"\"\"\n",
        "\n",
        "        self.validate_params(qubits, depth, goal_ce)\n",
        "\n",
        "        # Validate goal_ce format\n",
        "        ce_str = f\"{int(goal_ce * 100):02d}\"\n",
        "\n",
        "        # Construct file path\n",
        "        qubit_dir = f\"{qubits}_Qubits\"\n",
        "        depth_dir = f\"Depth_{depth}\"\n",
        "        filename = f\"hwe_{qubits}q_ps_{ce_str}_{depth}_weights.npy\"\n",
        "\n",
        "        return os.path.join(self.base_path, qubit_dir, depth_dir, filename)\n",
        "\n",
        "    def load_weights(self, qubits: int, depth: int, goal_ce: float) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Load weights from the repository.\n",
        "\n",
        "        Args:\n",
        "            qubits: Number of qubits\n",
        "            input_type: Type of input states\n",
        "            goal_ce: Goal concentratable entanglement (0-1)\n",
        "            depth: Circuit depth\n",
        "\n",
        "        Returns:\n",
        "            Weights as numpy array\n",
        "        \"\"\"\n",
        "        file_path = self._construct_filepath(qubits, depth, goal_ce)\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"Weights file not found at: {file_path}\")\n",
        "\n",
        "        return np.load(file_path)\n",
        "\n",
        "    def hardware_efficient_ansatz(self, qc, params, qubits, depth):\n",
        "        \"\"\"Adds hardware-efficient ansatz to a QuantumCircuit\"\"\"\n",
        "        param_idx = 0\n",
        "        for d in range(depth):\n",
        "            # Single-qubit rotations\n",
        "            for q in range(qubits):\n",
        "                qc.rx(params[param_idx], q)\n",
        "                qc.ry(params[param_idx+1], q)\n",
        "                qc.rz(params[param_idx+2], q)\n",
        "                param_idx += 3\n",
        "\n",
        "            # Entangling layer\n",
        "            for q in range(qubits - 1):\n",
        "                qc.cx(q, q+1)\n",
        "            if qubits > 1:\n",
        "                qc.cx(qubits-1, 0)\n",
        "\n",
        "    def generate_states(self, qubits: int, depth: int, goal_ce: float,\n",
        "                       num_samples: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        weights = self.load_weights(qubits, depth, goal_ce)\n",
        "        simulator = Aer.get_backend('aer_simulator')\n",
        "\n",
        "        # Validate parameter count\n",
        "        expected_params = depth * qubits * 3\n",
        "        if len(weights.flatten()) != expected_params:\n",
        "            raise ValueError(f\"Parameter mismatch: {len(weights.flatten())} vs {expected_params}\")\n",
        "\n",
        "        input_states = []\n",
        "        output_states = []\n",
        "\n",
        "        for _ in range(num_samples):\n",
        "            input_state = np.random.randint(0, 2**qubits)\n",
        "            qc = QuantumCircuit(qubits)\n",
        "\n",
        "            # Initialize state\n",
        "            for q in range(qubits):\n",
        "                if (input_state >> q) & 1:\n",
        "                    qc.x(q)\n",
        "\n",
        "            # Create parameterized circuit\n",
        "            params = ParameterVector('Î¸', depth * qubits * 3)\n",
        "            self.hardware_efficient_ansatz(qc, params, qubits, depth)\n",
        "\n",
        "            # Bind loaded weights\n",
        "            bound_qc = qc.assign_parameters(weights.flatten())\n",
        "\n",
        "            # Simulate\n",
        "            bound_qc.save_statevector()\n",
        "            result = simulator.run(bound_qc).result()\n",
        "            statevector = result.get_statevector()\n",
        "\n",
        "            input_states.append(input_state)\n",
        "            output_states.append(statevector.data)\n",
        "\n",
        "        return np.array(input_states), np.array(output_states)\n",
        "\n",
        "    def save_dataset(self, input_states: np.ndarray, output_states: np.ndarray,\n",
        "                    save_dir: str, filename_prefix: str):\n",
        "        \"\"\"\n",
        "        Save generated dataset to files.\n",
        "\n",
        "        Args:\n",
        "            input_states: Array of input computational basis states\n",
        "            output_states: Array of output quantum states\n",
        "            save_dir: Directory to save files\n",
        "            filename_prefix: Prefix for output files\n",
        "        \"\"\"\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # Save input states\n",
        "        np.save(os.path.join(save_dir, f\"{filename_prefix}_inputs.npy\"), input_states)\n",
        "\n",
        "        # Save output states\n",
        "        np.save(os.path.join(save_dir, f\"{filename_prefix}_outputs.npy\"), output_states)\n",
        "\n",
        "    def create_classification_dataset(self,\n",
        "                                    entanglement_levels: List[float] = [0.15, 0.35, 0.45],\n",
        "                                    depths: int | list[int] = 3,\n",
        "                                    num_samples: int = 3000,\n",
        "                                    qubits: int = 4,\n",
        "                                    random_state: int = 42) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Create a classified dataset of quantum states with different entanglement levels.\n",
        "\n",
        "        Args:\n",
        "            entanglement_levels: List of target CE values for different classes\n",
        "            depths: Single depth for all classes or list of depths per class\n",
        "            num_samples: Total number of samples in the dataset\n",
        "            qubits: Number of qubits in generated states\n",
        "            random_state: Seed for reproducible shuffling\n",
        "\n",
        "        Returns:\n",
        "            X: Array of quantum states (num_samples, 2**qubits)\n",
        "            y: Array of class labels (num_samples,)\n",
        "\n",
        "        Raises:\n",
        "            ValueError: For invalid input combinations\n",
        "        \"\"\"\n",
        "        # Input validation\n",
        "        if isinstance(depths, int):\n",
        "            depths = [depths] * len(entanglement_levels)\n",
        "        elif len(depths) != len(entanglement_levels):\n",
        "            raise ValueError(\"Length of depths must match entanglement_levels\")\n",
        "\n",
        "        for ce_level, depth in zip(entanglement_levels, depths):\n",
        "            self.validate_params(qubits, depth, ce_level)\n",
        "\n",
        "        # Calculate samples per class with remainder distribution\n",
        "        samples_per_class, remainder = divmod(num_samples, len(entanglement_levels))\n",
        "        class_samples = [samples_per_class + (1 if i < remainder else 0)\n",
        "                        for i in range(len(entanglement_levels))]\n",
        "\n",
        "        # Generate states for each class\n",
        "        X, y = [], []\n",
        "        for class_idx, (ce_level, depth, n_samples) in enumerate(zip(entanglement_levels,\n",
        "                                                                depths,\n",
        "                                                                class_samples)):\n",
        "            print(f\"Generating class {class_idx+1}/{len(entanglement_levels)}: \"\n",
        "                f\"CE={ce_level}, depth={depth}, samples={n_samples}\")\n",
        "\n",
        "            _, states = self.generate_states(\n",
        "                qubits=qubits,\n",
        "                depth=depth,\n",
        "                goal_ce=ce_level,\n",
        "                num_samples=n_samples\n",
        "            )\n",
        "\n",
        "            X.append(states)\n",
        "            y.append(np.full(n_samples, class_idx))\n",
        "\n",
        "        # Combine and shuffle\n",
        "        X = np.concatenate(X)\n",
        "        y = np.concatenate(y)\n",
        "        rng = np.random.default_rng(random_state)\n",
        "        indices = rng.permutation(len(X))\n",
        "\n",
        "        return X[indices], y[indices]\n",
        "\n",
        "# Example usage in the __main__ block\n",
        "if __name__ == \"__main__\":\n",
        "    generator = HardwareEfficientDatasetGenerator(base_path=\"Hardware_Efficient\")\n",
        "\n",
        "    # Classification dataset example\n",
        "    print(\"\\nGenerating classification dataset:\")\n",
        "    qubits = 3\n",
        "    X, y = generator.create_classification_dataset(\n",
        "        entanglement_levels=[0.15, 0.35],\n",
        "        depths=[3, 5],\n",
        "        qubits=qubits,\n",
        "        num_samples=1000\n",
        "    )\n",
        "\n",
        "    print(\"\\nClassification dataset stats:\")\n",
        "    print(f\"Total samples: {len(X)}\")\n",
        "    print(f\"Class distribution: {np.bincount(y)}\")\n",
        "    print(f\"State shape: {X[0].shape}\") # 2**qubits\n",
        "    print(f\"First state:\\n{X[0]}\")\n",
        "    print(f\"Class label: {y[0]}\")\n",
        "\n",
        "    # Save classification dataset\n",
        "    generator.save_dataset(\n",
        "        input_states=X,  # Dummy inputs since we're using class labels\n",
        "        output_states=y,\n",
        "        save_dir=\"classification_datasets\",\n",
        "        filename_prefix=f\"{qubits}q_ce_classification\"\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}