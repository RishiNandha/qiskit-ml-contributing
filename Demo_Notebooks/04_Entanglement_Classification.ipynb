{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This code is part of a Qiskit project.\n",
        "#\n",
        "# (C) Copyright IBM 2025.\n",
        "#\n",
        "# This code is licensed under the Apache License, Version 2.0. You may\n",
        "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
        "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
        "#\n",
        "# Any modifications or derivative works of this code must retain this\n",
        "# copyright notice, and modified files need to carry a notice indicating\n",
        "# that they have been altered from the originals.\n",
        "\n",
        "\"\"\"\n",
        "Entanglement Concentration\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "from qiskit import QuantumCircuit\n",
        "\n",
        "from ..utils import algorithm_globals\n",
        "\n",
        "\n",
        "# pylint: disable=too-many-positional-arguments\n",
        "def entanglement_concentration_data(\n",
        "    training_size: int,\n",
        "    test_size: int,\n",
        "    n: int,\n",
        "    mode: str = \"easy\",\n",
        "    one_hot: bool = True,\n",
        "    include_sample_total: bool = False,\n",
        "    sampling_method: str = \"grid\",\n",
        "    class_labels: list | None = None,\n",
        ") -> (\n",
        "    tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n",
        "    | tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n",
        "):\n",
        "    r\"\"\"\n",
        "    Generates a dataset that comprises of Quantum States with two different\n",
        "    amounts of Concentration Of Entanglement (CE) and their corresponding class labels.\n",
        "    These states are generated by the effect of two different pre-trained ansatz\n",
        "    on fully seperable input states, training procedure and data is used in courtesy\n",
        "    of L Schatzki et el. [1]. The datapoints can be fully separated using the SWAP\n",
        "    test outlined in [2]. First, input states are randomly generated from a\n",
        "    uniform distribution, using a sampling method determined by the ``sampling_method``\n",
        "    argument. Next, based on the ``mode`` argument, two pre-trained circuits \"A\" and \"B\"\n",
        "    are used for generating datapoints.\n",
        "\n",
        "    CE can be interpreted as a measure of correlation between the different qubits.\n",
        "    The ``mode`` argument supports two options. ``\"easy\"`` gives datapoints with CE\n",
        "    values of ``0.0`` for first class and ``0.35`` for the second class. ``\"hard\"`` mode\n",
        "    gives datapoints with CE of ``0.15`` for first class and ``0.25`` for second class.\n",
        "    The user's classifiers can be benchmarked against these modes for their ability to\n",
        "    separate the data into two classes based on CE.\n",
        "\n",
        "    Current implementation supports only ``n`` values of 3, 4 and 8.\n",
        "\n",
        "    ``sampling_method`` argument supports two options. ``\"random_basis\"`` and ``\"standard_basis\"``.\n",
        "    Random basis generates Qubit states that are sampled randomly in the Bloch Sphere and takes the\n",
        "    tensor product of all the qubits to build the input state. Standard basis generates only states\n",
        "    that fall on the axes of the Bloch Sphere before taking the tensor product.\n",
        "\n",
        "    **References:**\n",
        "\n",
        "    [1] Havlíček V, Córcoles AD, Temme K, Harrow AW, Kandala A, Chow JM,\n",
        "    Gambetta JM. *Supervised learning with quantum-enhanced feature spaces*.\n",
        "    Nature. 2019 Mar;567(7747):209–212.\n",
        "    `arXiv:1804.11326 <https://arxiv.org/abs/1804.11326>`_\n",
        "\n",
        "    Parameters:\n",
        "        training_size : Number of training samples per class.\n",
        "        test_size :  Number of testing samples per class.\n",
        "        n : Number of qubits (dimension of the feature space).\n",
        "        gap : Separation gap :math:`\\Delta` used when ``labelling_method=\"expectation\"``.\n",
        "            Default is 0.\n",
        "        plot_data : If True, plots the sampled data (disabled automatically if\n",
        "            ``n > 3``). Default is False.\n",
        "        one_hot : If True, returns labels in one-hot format. Default is True.\n",
        "        include_sample_total : If True, the function also returns the total number\n",
        "            of accepted samples. Default is False.\n",
        "        entanglement : Determines which second-order terms :math:`Z_i Z_j` appear in\n",
        "            :math:`U_{\\Phi(\\vec{x})}`. The options are:\n",
        "\n",
        "                * ``\"linear\"``: Includes terms :math:`Z_i Z_{i+1}`.\n",
        "                * ``\"circular\"``: Includes ``\"linear\"`` terms plus :math:`Z_{n-1}Z_0`.\n",
        "                * ``\"full\"``: Includes all pairwise terms :math:`Z_i Z_j`.\n",
        "\n",
        "            Default is ``\"full\"``.\n",
        "        sampling_method: The method used to generate uniform samples :math:`\\vec{x}`.\n",
        "            Choices are:\n",
        "\n",
        "                * ``\"grid\"``: Chooses points from a uniform grid (supported only if ``n <= 3``)\n",
        "                * ``\"hypercube\"``: Uses a variant of Latin Hypercube sampling for stratification\n",
        "                * ``\"sobol\"``: Uses Sobol sequences\n",
        "\n",
        "            Default is ``\"grid\"``.\n",
        "        divisions : Must be specified if ``sampling_method=\"hypercube\"``. This parameter\n",
        "            determines the number of stratifications along each dimension. Recommended\n",
        "            to be chosen close to ``training_size``.\n",
        "        labelling_method : Method for assigning labels. The options are:\n",
        "\n",
        "                * ``\"expectation\"``: Uses the expectation value of the observable.\n",
        "                * ``\"measurement\"``: Performs a measurement in the computational basis.\n",
        "\n",
        "            Default is ``\"expectation\"``.\n",
        "        class_labels : Custom labels for the two classes when one-hot is not enabled.\n",
        "            If not provided, the labels default to ``-1`` and ``+1``\n",
        "\n",
        "    Returns:\n",
        "        Tuple\n",
        "        containing the following:\n",
        "\n",
        "        * **training_features** : ``np.ndarray``\n",
        "        * **training_labels** : ``np.ndarray``\n",
        "        * **testing_features** : ``np.ndarray``\n",
        "        * **testing_labels** : ``np.ndarray``\n",
        "\n",
        "        If ``include_sample_total=True``, a fifth element (``np.ndarray``) is included\n",
        "        that specifies the total number of accepted samples.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "8M9smY9lgZFt"
      },
      "id": "8M9smY9lgZFt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is part of a Qiskit project.\n",
        "#\n",
        "# (C) Copyright IBM 2025.\n",
        "#\n",
        "# This code is licensed under the Apache License, Version 2.0. You may\n",
        "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
        "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
        "#\n",
        "# Any modifications or derivative works of this code must retain this\n",
        "# copyright notice, and modified files need to carry a notice indicating\n",
        "# that they have been altered from the originals.\n",
        "\n",
        "\"\"\"\n",
        "Test Entanglement Concentration\n",
        "\"\"\"\n",
        "\n",
        "from test import QiskitMachineLearningTestCase\n",
        "\n",
        "import unittest"
      ],
      "metadata": {
        "id": "Yv7Ft66kjL4g"
      },
      "id": "Yv7Ft66kjL4g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58NgCmZSgYFV"
      },
      "id": "58NgCmZSgYFV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LIZmX7TAOMf7"
      },
      "id": "LIZmX7TAOMf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "xjObC5pqOMxh"
      },
      "id": "xjObC5pqOMxh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f291447-df88-4f5c-be51-6273d598b470",
      "metadata": {
        "id": "4f291447-df88-4f5c-be51-6273d598b470"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from typing import List, Tuple\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.quantum_info import Statevector\n",
        "from qiskit.circuit import ParameterVector\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class HardwareEfficientDatasetGenerator:\n",
        "    def __init__(self, base_path: str = \"Hardware_Efficient\"):\n",
        "        self.base_path = base_path\n",
        "        self.supported_qubits = [3, 4, 8]\n",
        "        self.supported_depths_34 = list(range(1, 7))\n",
        "        self.supported_depths_8 = [5, 6]\n",
        "        self.supported_ce_34 = [0.05, 0.15, 0.25, 0.35]\n",
        "        self.supported_ce_8_6 = [0.10, 0.25]\n",
        "        self.supported_ce_8_5 = [0.15, 0.40, 0.45]\n",
        "\n",
        "    def validate_params(self, qubits: int, depth: int, goal_ce: float) -> bool:\n",
        "        # Validate inputs\n",
        "        if qubits not in self.supported_qubits:\n",
        "            raise ValueError(f\"Unsupported qubit count: {qubits}. Choose from {self.supported_qubits}\")\n",
        "\n",
        "        if (qubits == 8):\n",
        "            if depth not in self.supported_depths_8:\n",
        "                raise ValueError(f\"Unsupported depth: {depth}. Choose from {self.supported_depths_8}\")\n",
        "            if (depth == 6):\n",
        "                if goal_ce not in self.supported_ce_8_6:\n",
        "                    raise ValueError(f\"Unsupported CE value: {goal_ce}. Choose from {self.supported_ce_8_6}\")\n",
        "            else:\n",
        "                if goal_ce not in self.supported_ce_8_5:\n",
        "                    raise ValueError(f\"Unsupported CE value: {goal_ce}. Choose from {self.supported_ce_8_5}\")\n",
        "        else:\n",
        "            if depth not in self.supported_depths_34:\n",
        "                raise ValueError(f\"Unsupported depth: {depth}. Choose from {self.supported_depths_34}\")\n",
        "            if goal_ce not in self.supported_ce_34:\n",
        "                raise ValueError(f\"Unsupported CE value: {goal_ce}. Choose from {self.supported_ce_34}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _construct_filepath(self, qubits: int, depth: int, goal_ce: float) -> str:\n",
        "        \"\"\"\n",
        "        Construct the full file path based on parameters and directory structure.\n",
        "\n",
        "        Args:\n",
        "            qubits: Number of qubits (3 or 4)\n",
        "            depth: Circuit depth (1-6)\n",
        "            goal_ce: Target concentratable entanglement (0.05, 0.15, 0.25, 0.35, 0.5)\n",
        "\n",
        "        Returns:\n",
        "            Full path to .npy weights file\n",
        "        \"\"\"\n",
        "\n",
        "        self.validate_params(qubits, depth, goal_ce)\n",
        "\n",
        "        # Validate goal_ce format\n",
        "        ce_str = f\"{int(goal_ce * 100):02d}\"\n",
        "\n",
        "        # Construct file path\n",
        "        qubit_dir = f\"{qubits}_Qubits\"\n",
        "        depth_dir = f\"Depth_{depth}\"\n",
        "        filename = f\"hwe_{qubits}q_ps_{ce_str}_{depth}_weights.npy\"\n",
        "\n",
        "        return os.path.join(self.base_path, qubit_dir, depth_dir, filename)\n",
        "\n",
        "    def load_weights(self, qubits: int, depth: int, goal_ce: float) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Load weights from the repository.\n",
        "\n",
        "        Args:\n",
        "            qubits: Number of qubits\n",
        "            input_type: Type of input states\n",
        "            goal_ce: Goal concentratable entanglement (0-1)\n",
        "            depth: Circuit depth\n",
        "\n",
        "        Returns:\n",
        "            Weights as numpy array\n",
        "        \"\"\"\n",
        "        file_path = self._construct_filepath(qubits, depth, goal_ce)\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"Weights file not found at: {file_path}\")\n",
        "\n",
        "        return np.load(file_path)\n",
        "\n",
        "    def hardware_efficient_ansatz(self, qc, params, qubits, depth):\n",
        "        \"\"\"Adds hardware-efficient ansatz to a QuantumCircuit\"\"\"\n",
        "        param_idx = 0\n",
        "        for d in range(depth):\n",
        "            # Single-qubit rotations\n",
        "            for q in range(qubits):\n",
        "                qc.rx(params[param_idx], q)\n",
        "                qc.ry(params[param_idx+1], q)\n",
        "                qc.rz(params[param_idx+2], q)\n",
        "                param_idx += 3\n",
        "\n",
        "            # Entangling layer\n",
        "            for q in range(qubits - 1):\n",
        "                qc.cx(q, q+1)\n",
        "            if qubits > 1:\n",
        "                qc.cx(qubits-1, 0)\n",
        "\n",
        "    def generate_states(self, qubits: int, depth: int, goal_ce: float,\n",
        "                       num_samples: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        weights = self.load_weights(qubits, depth, goal_ce)\n",
        "        simulator = Aer.get_backend('aer_simulator')\n",
        "\n",
        "        # Validate parameter count\n",
        "        expected_params = depth * qubits * 3\n",
        "        if len(weights.flatten()) != expected_params:\n",
        "            raise ValueError(f\"Parameter mismatch: {len(weights.flatten())} vs {expected_params}\")\n",
        "\n",
        "        input_states = []\n",
        "        output_states = []\n",
        "\n",
        "        for _ in range(num_samples):\n",
        "            input_state = np.random.randint(0, 2**qubits)\n",
        "            qc = QuantumCircuit(qubits)\n",
        "\n",
        "            # Initialize state\n",
        "            for q in range(qubits):\n",
        "                if (input_state >> q) & 1:\n",
        "                    qc.x(q)\n",
        "\n",
        "            # Create parameterized circuit\n",
        "            params = ParameterVector('θ', depth * qubits * 3)\n",
        "            self.hardware_efficient_ansatz(qc, params, qubits, depth)\n",
        "\n",
        "            # Bind loaded weights\n",
        "            bound_qc = qc.assign_parameters(weights.flatten())\n",
        "\n",
        "            # Simulate\n",
        "            bound_qc.save_statevector()\n",
        "            result = simulator.run(bound_qc).result()\n",
        "            statevector = result.get_statevector()\n",
        "\n",
        "            input_states.append(input_state)\n",
        "            output_states.append(statevector.data)\n",
        "\n",
        "        return np.array(input_states), np.array(output_states)\n",
        "\n",
        "    def save_dataset(self, input_states: np.ndarray, output_states: np.ndarray,\n",
        "                    save_dir: str, filename_prefix: str):\n",
        "        \"\"\"\n",
        "        Save generated dataset to files.\n",
        "\n",
        "        Args:\n",
        "            input_states: Array of input computational basis states\n",
        "            output_states: Array of output quantum states\n",
        "            save_dir: Directory to save files\n",
        "            filename_prefix: Prefix for output files\n",
        "        \"\"\"\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # Save input states\n",
        "        np.save(os.path.join(save_dir, f\"{filename_prefix}_inputs.npy\"), input_states)\n",
        "\n",
        "        # Save output states\n",
        "        np.save(os.path.join(save_dir, f\"{filename_prefix}_outputs.npy\"), output_states)\n",
        "\n",
        "    def create_classification_dataset(self,\n",
        "                                    entanglement_levels: List[float] = [0.15, 0.35, 0.45],\n",
        "                                    depths: int | list[int] = 3,\n",
        "                                    num_samples: int = 3000,\n",
        "                                    qubits: int = 4,\n",
        "                                    random_state: int = 42) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Create a classified dataset of quantum states with different entanglement levels.\n",
        "\n",
        "        Args:\n",
        "            entanglement_levels: List of target CE values for different classes\n",
        "            depths: Single depth for all classes or list of depths per class\n",
        "            num_samples: Total number of samples in the dataset\n",
        "            qubits: Number of qubits in generated states\n",
        "            random_state: Seed for reproducible shuffling\n",
        "\n",
        "        Returns:\n",
        "            X: Array of quantum states (num_samples, 2**qubits)\n",
        "            y: Array of class labels (num_samples,)\n",
        "\n",
        "        Raises:\n",
        "            ValueError: For invalid input combinations\n",
        "        \"\"\"\n",
        "        # Input validation\n",
        "        if isinstance(depths, int):\n",
        "            depths = [depths] * len(entanglement_levels)\n",
        "        elif len(depths) != len(entanglement_levels):\n",
        "            raise ValueError(\"Length of depths must match entanglement_levels\")\n",
        "\n",
        "        for ce_level, depth in zip(entanglement_levels, depths):\n",
        "            self.validate_params(qubits, depth, ce_level)\n",
        "\n",
        "        # Calculate samples per class with remainder distribution\n",
        "        samples_per_class, remainder = divmod(num_samples, len(entanglement_levels))\n",
        "        class_samples = [samples_per_class + (1 if i < remainder else 0)\n",
        "                        for i in range(len(entanglement_levels))]\n",
        "\n",
        "        # Generate states for each class\n",
        "        X, y = [], []\n",
        "        for class_idx, (ce_level, depth, n_samples) in enumerate(zip(entanglement_levels,\n",
        "                                                                depths,\n",
        "                                                                class_samples)):\n",
        "            print(f\"Generating class {class_idx+1}/{len(entanglement_levels)}: \"\n",
        "                f\"CE={ce_level}, depth={depth}, samples={n_samples}\")\n",
        "\n",
        "            _, states = self.generate_states(\n",
        "                qubits=qubits,\n",
        "                depth=depth,\n",
        "                goal_ce=ce_level,\n",
        "                num_samples=n_samples\n",
        "            )\n",
        "\n",
        "            X.append(states)\n",
        "            y.append(np.full(n_samples, class_idx))\n",
        "\n",
        "        # Combine and shuffle\n",
        "        X = np.concatenate(X)\n",
        "        y = np.concatenate(y)\n",
        "        rng = np.random.default_rng(random_state)\n",
        "        indices = rng.permutation(len(X))\n",
        "\n",
        "        return X[indices], y[indices]\n",
        "\n",
        "# Example usage in the __main__ block\n",
        "if __name__ == \"__main__\":\n",
        "    generator = HardwareEfficientDatasetGenerator(base_path=\"Hardware_Efficient\")\n",
        "\n",
        "    # Classification dataset example\n",
        "    print(\"\\nGenerating classification dataset:\")\n",
        "    qubits = 3\n",
        "    X, y = generator.create_classification_dataset(\n",
        "        entanglement_levels=[0.15, 0.35],\n",
        "        depths=[3, 5],\n",
        "        qubits=qubits,\n",
        "        num_samples=1000\n",
        "    )\n",
        "\n",
        "    print(\"\\nClassification dataset stats:\")\n",
        "    print(f\"Total samples: {len(X)}\")\n",
        "    print(f\"Class distribution: {np.bincount(y)}\")\n",
        "    print(f\"State shape: {X[0].shape}\") # 2**qubits\n",
        "    print(f\"First state:\\n{X[0]}\")\n",
        "    print(f\"Class label: {y[0]}\")\n",
        "\n",
        "    # Save classification dataset\n",
        "    generator.save_dataset(\n",
        "        input_states=X,  # Dummy inputs since we're using class labels\n",
        "        output_states=y,\n",
        "        save_dir=\"classification_datasets\",\n",
        "        filename_prefix=f\"{qubits}q_ce_classification\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is part of a Qiskit project.\n",
        "#\n",
        "# (C) Copyright IBM 2018, 2025.\n",
        "#\n",
        "# This code is licensed under the Apache License, Version 2.0. You may\n",
        "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
        "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
        "#\n",
        "# Any modifications or derivative works of this code must retain this\n",
        "# copyright notice, and modified files need to carry a notice indicating\n",
        "# that they have been altered from the originals.\n",
        "\n",
        "\"\"\"\n",
        "Ad Hoc Dataset\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import warnings\n",
        "import itertools as it\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats.qmc import Sobol\n",
        "from qiskit.utils import optionals\n",
        "\n",
        "from ..utils import algorithm_globals\n",
        "\n",
        "\n",
        "# pylint: disable=too-many-positional-arguments\n",
        "def ad_hoc_data(\n",
        "    training_size: int,\n",
        "    test_size: int,\n",
        "    n: int,\n",
        "    gap: int = 0,\n",
        "    plot_data: bool = False,\n",
        "    one_hot: bool = True,\n",
        "    include_sample_total: bool = False,\n",
        "    entanglement: str = \"full\",\n",
        "    sampling_method: str = \"grid\",\n",
        "    divisions: int = 0,\n",
        "    labelling_method: str = \"expectation\",\n",
        "    class_labels: list | None = None,\n",
        ") -> (\n",
        "    tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n",
        "    | tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n",
        "):\n",
        "    r\"\"\"\n",
        "    Generates a dataset that can be fully separated by\n",
        "    :class:`~qiskit.circuit.library.ZZFeatureMap` according to the procedure\n",
        "    outlined in [1]. First, vectors :math:`\\vec{x} \\in (0, 2\\pi]^{n}` are generated from a\n",
        "    uniform distribution, using a sampling method determined by the ``sampling_method``\n",
        "    argument. Next, a feature map is applied:\n",
        "\n",
        "    .. math::\n",
        "       |\\Phi(\\vec{x})\\rangle\n",
        "       = U_{\\Phi(\\vec{x})} \\, H^{\\otimes n} \\,\n",
        "         U_{\\Phi(\\vec{x})} \\, H^{\\otimes n} \\, |0^{\\otimes n}\\rangle\n",
        "\n",
        "    where\n",
        "\n",
        "    .. math::\n",
        "       U_{\\Phi(\\vec{x})}\n",
        "       = \\exp\\Bigl(i \\sum_{S \\subseteq [n]} \\phi_S(\\vec{x}) \\prod_{i \\in S} Z_i\\Bigr),\n",
        "\n",
        "    and\n",
        "\n",
        "    .. math::\n",
        "        \\begin{cases}\\phi_{\\{i, j\\}} = (\\pi - x_i)(\\pi - x_j) \\\\\n",
        "        \\phi_{\\{i\\}} = x_i \\end{cases}\n",
        "\n",
        "    The choice of second-order terms :math:`Z_i Z_j` in the above summation depends\n",
        "    on the ``entanglement`` argument (``\"linear\"``, ``\"circular\"``, or\n",
        "    ``\"full\"``). See arguments for more information.\n",
        "\n",
        "    An observable is then defined as\n",
        "\n",
        "    .. math::\n",
        "       O = V^\\dagger \\bigl(\\prod_i Z_i\\bigr) V\n",
        "\n",
        "    where :math:`V` is a randomly generated unitary matrix. Depending on the\n",
        "    ``labelling_method``, if ``\"expectation\"`` is used, the expectation value\n",
        "    :math:`\\langle \\Phi(\\vec{x})| O |\\Phi(\\vec{x})\\rangle` is compared to the\n",
        "    gap parameter :math:`\\Delta` (from ``gap``) to assign :math:`\\pm 1` labels.\n",
        "    if ``\"measurement\"`` is used, a simple measurement in the computational\n",
        "    basis is performed to assign labels.\n",
        "\n",
        "    **References:**\n",
        "\n",
        "    [1] Havlíček V, Córcoles AD, Temme K, Harrow AW, Kandala A, Chow JM,\n",
        "    Gambetta JM. *Supervised learning with quantum-enhanced feature spaces*.\n",
        "    Nature. 2019 Mar;567(7747):209–212.\n",
        "    `arXiv:1804.11326 <https://arxiv.org/abs/1804.11326>`_\n",
        "\n",
        "    Parameters:\n",
        "        training_size : Number of training samples per class.\n",
        "        test_size :  Number of testing samples per class.\n",
        "        n : Number of qubits (dimension of the feature space).\n",
        "        gap : Separation gap :math:`\\Delta` used when ``labelling_method=\"expectation\"``.\n",
        "            Default is 0.\n",
        "        plot_data : If True, plots the sampled data (disabled automatically if\n",
        "            ``n > 3``). Default is False.\n",
        "        one_hot : If True, returns labels in one-hot format. Default is True.\n",
        "        include_sample_total : If True, the function also returns the total number\n",
        "            of accepted samples. Default is False.\n",
        "        entanglement : Determines which second-order terms :math:`Z_i Z_j` appear in\n",
        "            :math:`U_{\\Phi(\\vec{x})}`. The options are:\n",
        "\n",
        "                * ``\"linear\"``: Includes terms :math:`Z_i Z_{i+1}`.\n",
        "                * ``\"circular\"``: Includes ``\"linear\"`` terms plus :math:`Z_{n-1}Z_0`.\n",
        "                * ``\"full\"``: Includes all pairwise terms :math:`Z_i Z_j`.\n",
        "\n",
        "            Default is ``\"full\"``.\n",
        "        sampling_method: The method used to generate uniform samples :math:`\\vec{x}`.\n",
        "            Choices are:\n",
        "\n",
        "                * ``\"grid\"``: Chooses points from a uniform grid (supported only if ``n <= 3``)\n",
        "                * ``\"hypercube\"``: Uses a variant of Latin Hypercube sampling for stratification\n",
        "                * ``\"sobol\"``: Uses Sobol sequences\n",
        "\n",
        "            Default is ``\"grid\"``.\n",
        "        divisions : Must be specified if ``sampling_method=\"hypercube\"``. This parameter\n",
        "            determines the number of stratifications along each dimension. Recommended\n",
        "            to be chosen close to ``training_size``.\n",
        "        labelling_method : Method for assigning labels. The options are:\n",
        "\n",
        "                * ``\"expectation\"``: Uses the expectation value of the observable.\n",
        "                * ``\"measurement\"``: Performs a measurement in the computational basis.\n",
        "\n",
        "            Default is ``\"expectation\"``.\n",
        "        class_labels : Custom labels for the two classes when one-hot is not enabled.\n",
        "            If not provided, the labels default to ``-1`` and ``+1``\n",
        "\n",
        "    Returns:\n",
        "        Tuple\n",
        "        containing the following:\n",
        "\n",
        "        * **training_features** : ``np.ndarray``\n",
        "        * **training_labels** : ``np.ndarray``\n",
        "        * **testing_features** : ``np.ndarray``\n",
        "        * **testing_labels** : ``np.ndarray``\n",
        "\n",
        "        If ``include_sample_total=True``, a fifth element (``np.ndarray``) is included\n",
        "        that specifies the total number of accepted samples.\n",
        "    \"\"\"\n",
        "\n",
        "    # Default Value\n",
        "    if class_labels is None:\n",
        "        class_labels = [0, 1]\n",
        "\n",
        "    # Errors\n",
        "    if training_size < 0:\n",
        "        raise ValueError(\"Training size can't be less than 0\")\n",
        "    if test_size < 0:\n",
        "        raise ValueError(\"Test size can't be less than 0\")\n",
        "    if n <= 0:\n",
        "        raise ValueError(\"Number of qubits can't be less than 1\")\n",
        "    if gap < 0 and labelling_method == \"expectation\":\n",
        "        raise ValueError(\"Gap can't be less than 0\")\n",
        "    if entanglement not in {\"linear\", \"circular\", \"full\"}:\n",
        "        raise ValueError(\"Invalid entanglement type. Must be 'linear', 'circular', or 'full'.\")\n",
        "    if sampling_method not in {\"grid\", \"hypercube\", \"sobol\"}:\n",
        "        raise ValueError(\"Invalid sampling method. Must be 'grid', 'hypercube', or 'sobol'.\")\n",
        "    if divisions == 0 and sampling_method == \"hypercube\":\n",
        "        raise ValueError(\"Divisions must be set for 'hypercube' sampling.\")\n",
        "    if labelling_method not in {\"expectation\", \"measurement\"}:\n",
        "        raise ValueError(\"Invalid labelling method. Must be 'expectation' or 'measurement'.\")\n",
        "    if n > 3 and sampling_method == \"grid\":\n",
        "        raise ValueError(\"Grid sampling is unsupported for n > 3.\")\n",
        "\n",
        "    # Warnings\n",
        "    if n > 3 and plot_data:\n",
        "        warnings.warn(\n",
        "            \"Plotting for n > 3 is unsupported. Disabling plot_data.\",\n",
        "            UserWarning,\n",
        "        )\n",
        "        plot_data = False\n",
        "\n",
        "    if sampling_method == \"grid\" and (training_size + test_size) > 4000:\n",
        "        warnings.warn(\n",
        "            \"\"\"Grid Sampling for large number of samples is not recommended\n",
        "            and can lead to samples repeating in the training and testing sets\"\"\",\n",
        "            UserWarning,\n",
        "        )\n",
        "\n",
        "    # Initial State\n",
        "    dims = 2**n\n",
        "    psi_0 = np.ones(dims) / np.sqrt(dims)\n",
        "\n",
        "    # n-qubit Hadamard\n",
        "    h_n = _n_hadamard(n)\n",
        "\n",
        "    # Single qubit Z gates\n",
        "    z_diags = np.array([np.diag(_i_z(i, n)).reshape((1, -1)) for i in range(n)])\n",
        "\n",
        "    # Precompute ZZ Entanglements\n",
        "    zz_diags = {}\n",
        "    if entanglement == \"full\":\n",
        "        for i, j in it.combinations(range(n), 2):\n",
        "            zz_diags[(i, j)] = z_diags[i] * z_diags[j]\n",
        "    else:\n",
        "        for i in range(n - 1):\n",
        "            zz_diags[(i, i + 1)] = z_diags[i] * z_diags[i + 1]\n",
        "        if entanglement == \"circular\":\n",
        "            zz_diags[(n - 1, 0)] = z_diags[n - 1] * z_diags[0]\n",
        "\n",
        "    # n-qubit Z gate: notice that h_n[0,:] has the same elements as diagonal of z_n\n",
        "    z_n = _n_z(h_n)\n",
        "\n",
        "    # V change of basis: Eigenbasis of a random hermitian will be a random unitary\n",
        "    v = _random_unitary(dims)\n",
        "\n",
        "    # Observable for labelling boundary\n",
        "    mat_o = v.conj().T @ z_n @ v\n",
        "\n",
        "    n_samples = training_size + test_size\n",
        "\n",
        "    # Labelling Methods\n",
        "    if labelling_method == \"expectation\":\n",
        "\n",
        "        def _lab_fn(psi_state):\n",
        "            return _exp_label(psi_state, gap, mat_o)\n",
        "\n",
        "    else:\n",
        "        eig = np.linalg.eigh(mat_o)\n",
        "\n",
        "        def _lab_fn(psi_state):\n",
        "            return _measure(psi_state, eig)\n",
        "\n",
        "    # Sampling Methods\n",
        "    if sampling_method == \"grid\":\n",
        "        a_features, b_features = _grid_sampling(\n",
        "            n, n_samples, z_diags, zz_diags, psi_0, h_n, _lab_fn\n",
        "        )\n",
        "    else:\n",
        "        if sampling_method == \"hypercube\":\n",
        "\n",
        "            def _samp_fn(a, b):\n",
        "                return _modified_lhc(a, b, divisions)\n",
        "\n",
        "        else:\n",
        "\n",
        "            def _samp_fn(a, b):\n",
        "                return _sobol_sampling(a, b)\n",
        "\n",
        "        a_features, b_features = _loop_sampling(\n",
        "            n,\n",
        "            n_samples,\n",
        "            z_diags,\n",
        "            zz_diags,\n",
        "            psi_0,\n",
        "            h_n,\n",
        "            _lab_fn,\n",
        "            _samp_fn,\n",
        "            sampling_method,\n",
        "        )\n",
        "\n",
        "    if plot_data:\n",
        "        _plot_ad_hoc_data(a_features, b_features, training_size)\n",
        "\n",
        "    x_train = np.concatenate((a_features[:training_size], b_features[:training_size]), axis=0)\n",
        "    x_test = np.concatenate((a_features[training_size:], b_features[training_size:]), axis=0)\n",
        "    if one_hot:\n",
        "        y_train = np.array([[1, 0]] * training_size + [[0, 1]] * training_size)\n",
        "        y_test = np.array([[1, 0]] * test_size + [[0, 1]] * test_size)\n",
        "    else:\n",
        "        y_train = np.array([class_labels[0]] * training_size + [class_labels[1]] * training_size)\n",
        "        y_test = np.array([class_labels[0]] * test_size + [class_labels[1]] * test_size)\n",
        "\n",
        "    if include_sample_total:\n",
        "        samples = np.array([n_samples * 2])\n",
        "        return (x_train, y_train, x_test, y_test, samples)\n",
        "\n",
        "    return (x_train, y_train, x_test, y_test)\n",
        "\n",
        "\n",
        "@optionals.HAS_MATPLOTLIB.require_in_call\n",
        "def _plot_ad_hoc_data(a_features: np.ndarray, b_features: np.ndarray, training_size: int) -> None:\n",
        "    \"\"\"Plot the ad hoc dataset.\n",
        "\n",
        "    Args:\n",
        "        a_features (np.ndarray): Class-A feature vectors.\n",
        "        b_features (np.ndarray): Class-B feature vectors.\n",
        "        training_size (int): Number of training samples to plot.\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    fig = plt.figure()\n",
        "    projection = \"3d\" if a_features.shape[1] == 3 else None\n",
        "    ax1 = fig.add_subplot(1, 1, 1, projection=projection)\n",
        "    ax1.scatter(*a_features[:training_size].T)\n",
        "    ax1.scatter(*b_features[:training_size].T)\n",
        "    ax1.set_title(\"Ad-hoc Data\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def _n_hadamard(n: int) -> np.ndarray:\n",
        "    \"\"\"Generate an n-qubit Hadamard matrix.\n",
        "\n",
        "    Args:\n",
        "        n (int): Number of qubits.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The n-qubit Hadamard matrix.\n",
        "    \"\"\"\n",
        "    base = np.array([[1, 1], [1, -1]]) / np.sqrt(2)\n",
        "    result = np.eye(1)\n",
        "    expo = n\n",
        "\n",
        "    while expo > 0:\n",
        "        if expo % 2 == 1:\n",
        "            result = np.kron(result, base)\n",
        "        base = np.kron(base, base)\n",
        "        expo //= 2\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def _i_z(i: int, n: int) -> np.ndarray:\n",
        "    \"\"\"Create the i-th single-qubit Z gate in an n-qubit system.\n",
        "\n",
        "    Args:\n",
        "        i (int): Index of the qubit.\n",
        "        n (int): Total number of qubits.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The Z gate acting on the i-th qubit.\n",
        "    \"\"\"\n",
        "    z = np.diag([1, -1])\n",
        "    i_1 = np.eye(2**i)\n",
        "    i_2 = np.eye(2 ** (n - i - 1))\n",
        "\n",
        "    result = np.kron(i_1, z)\n",
        "    result = np.kron(result, i_2)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def _n_z(h_n: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Generate an n-qubit Z gate from the n-qubit Hadamard matrix.\n",
        "\n",
        "    Args:\n",
        "        h_n (np.ndarray): n-qubit Hadamard matrix.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The n-qubit Z gate.\n",
        "    \"\"\"\n",
        "    res = np.diag(h_n)\n",
        "    res = np.sign(res)\n",
        "    res = np.diag(res)\n",
        "    return res\n",
        "\n",
        "\n",
        "def _modified_lhc(n: int, n_samples: int, n_div: int) -> np.ndarray:\n",
        "    \"\"\"Generate samples using modified Latin Hypercube Sampling.\n",
        "\n",
        "    Args:\n",
        "        n (int): Dimensionality of the data.\n",
        "        n_samples (int): Number of samples to generate.\n",
        "        n_div (int): Number of divisions for stratified sampling.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Generated samples.\n",
        "    \"\"\"\n",
        "    samples = np.empty((n_samples, n), dtype=float)\n",
        "    bin_size = 2 * np.pi / n_div\n",
        "    n_passes = (n_samples + n_div - 1) // n_div\n",
        "\n",
        "    all_bins = np.tile(np.arange(n_div), n_passes)\n",
        "\n",
        "    for dim in range(n):\n",
        "        algorithm_globals.random.shuffle(all_bins)\n",
        "        chosen_bins = all_bins[:n_samples]\n",
        "        offsets = algorithm_globals.random.random(n_samples)\n",
        "        samples[:, dim] = (chosen_bins + offsets) * bin_size\n",
        "\n",
        "    return samples\n",
        "\n",
        "\n",
        "def _sobol_sampling(n: int, n_samples: int) -> np.ndarray:\n",
        "    \"\"\"Generate samples using Sobol sequence sampling.\n",
        "\n",
        "    Args:\n",
        "        n (int): Dimensionality of the data.\n",
        "        n_samples (int): Number of samples to generate.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Generated samples scaled to the interval [0, 2π].\n",
        "    \"\"\"\n",
        "    sampler = Sobol(d=n, scramble=True)\n",
        "    p = 2 * np.pi * sampler.random(n_samples)\n",
        "    return p\n",
        "\n",
        "\n",
        "def _phi_i(x_vecs: np.ndarray, i: int) -> np.ndarray:\n",
        "    \"\"\"Compute the φ_i term for a given dimension.\n",
        "\n",
        "    Args:\n",
        "        x_vecs (np.ndarray): Input sample vectors.\n",
        "        i (int): Dimension index.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Computed φ_i values.\n",
        "    \"\"\"\n",
        "    return x_vecs[:, i].reshape((-1, 1))\n",
        "\n",
        "\n",
        "def _phi_ij(x_vecs: np.ndarray, i: int, j: int) -> np.ndarray:\n",
        "    \"\"\"Compute the φ_ij term for given dimensions.\n",
        "\n",
        "    Args:\n",
        "        x_vecs (np.ndarray): Input sample vectors.\n",
        "        i (int): First dimension index.\n",
        "        j (int): Second dimension index.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Computed φ_ij values.\n",
        "    \"\"\"\n",
        "    return ((np.pi - x_vecs[:, i]) * (np.pi - x_vecs[:, j])).reshape((-1, 1))\n",
        "\n",
        "\n",
        "def _random_unitary(dims):\n",
        "    a = np.array(\n",
        "        algorithm_globals.random.random((dims, dims))\n",
        "        + 1j * algorithm_globals.random.random((dims, dims))\n",
        "    )\n",
        "    herm = a.conj().T @ a\n",
        "    eigvals, eigvecs = np.linalg.eig(herm)\n",
        "    idx = eigvals.argsort()[::-1]\n",
        "    v = eigvecs[:, idx]\n",
        "    return v\n",
        "\n",
        "\n",
        "def _loop_sampling(n, n_samples, z_diags, zz_diags, psi_0, h_n, lab_fn, samp_fn, sampling_method):\n",
        "    \"\"\"\n",
        "    Loop-based sampling routine to allocate feature vectors into two classes.\n",
        "\n",
        "    Args:\n",
        "        n (int): Number of qubits (feature dimension).\n",
        "        n_samples (int): Number of samples needed per class.\n",
        "        z_diags (np.ndarray): Array of single-qubit Z diagonal elements.\n",
        "        zz_diags (dict): Dictionary of ZZ-diagonal elements keyed by qubit\n",
        "            pairs.\n",
        "        O (np.ndarray): Observable for label determination.\n",
        "        psi_0 (np.ndarray): Initial state vector.\n",
        "        h_n (np.ndarray): n-qubit Hadamard matrix.\n",
        "        lab_fn (Callable): Labeling function (either expectation-based or\n",
        "            measurement-based).\n",
        "        samp_fn (Callable): Sampling function that generates feature vectors.\n",
        "        sampling_method (str): String indicating which sampling method is used\n",
        "            (\"grid\", \"hypercube\", or \"sobol\").\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]:\n",
        "            Two arrays of shape `(n_samples, n)`, each containing the sampled\n",
        "            feature vectors belonging to class A and class B, respectively.\n",
        "    \"\"\"\n",
        "    a_features = np.empty((n_samples, n), dtype=float)\n",
        "    b_features = np.empty((n_samples, n), dtype=float)\n",
        "\n",
        "    dims = 2**n\n",
        "    a_cur, b_cur = 0, 0\n",
        "    a_needed, b_needed = n_samples, n_samples\n",
        "\n",
        "    while a_needed > 0 or b_needed > 0:\n",
        "        n_pass = a_needed + b_needed\n",
        "\n",
        "        # Sobol works better with a 2^n just above n_pass\n",
        "        if sampling_method == \"sobol\":\n",
        "            n_pass = 2 ** ((n_pass - 1).bit_length())\n",
        "\n",
        "        # Stratified Sampling for x vector\n",
        "        x_vecs = samp_fn(n, n_pass)\n",
        "\n",
        "        pre_exp = np.zeros((n_pass, dims))\n",
        "\n",
        "        # First Order Terms\n",
        "        for i in range(n):\n",
        "            pre_exp += _phi_i(x_vecs, i) * z_diags[i]\n",
        "\n",
        "        # Second Order Terms\n",
        "        for i, j in zz_diags.keys():\n",
        "            pre_exp += _phi_ij(x_vecs, i, j) * zz_diags[(i, j)]\n",
        "\n",
        "        # Since pre_exp is purely diagonal, exp(A) = diag(exp(Aii))\n",
        "        post_exp = np.exp(1j * pre_exp)\n",
        "        uphi = np.zeros((n_pass, dims, dims), dtype=post_exp.dtype)\n",
        "        cols = range(dims)\n",
        "        uphi[:, cols, cols] = post_exp[:, cols]\n",
        "\n",
        "        psi = (uphi @ h_n @ uphi @ psi_0).reshape((-1, dims, 1))\n",
        "\n",
        "        # Labelling\n",
        "        raw_labels = lab_fn(psi)\n",
        "\n",
        "        if a_needed > 0:\n",
        "            a_indx = raw_labels == 1\n",
        "            a_count = min(int(np.sum(a_indx)), a_needed)\n",
        "            a_features[a_cur : a_cur + a_count] = x_vecs[a_indx][:a_count]\n",
        "            a_cur += a_count\n",
        "            a_needed -= a_count\n",
        "\n",
        "        if b_needed > 0:\n",
        "            b_indx = raw_labels == -1\n",
        "            b_count = min(int(np.sum(b_indx)), b_needed)\n",
        "            b_features[b_cur : b_cur + b_count] = x_vecs[b_indx][:b_count]\n",
        "            b_cur += b_count\n",
        "            b_needed -= b_count\n",
        "\n",
        "    return a_features, b_features\n",
        "\n",
        "\n",
        "def _exp_label(psi, gap, mat_o):\n",
        "    \"\"\"\n",
        "    Compute labels by comparing the expectation value of an observable to a gap.\n",
        "\n",
        "    Args:\n",
        "        psi (np.ndarray): Array of shape `(num_samples, dim, 1)` containing\n",
        "            the statevectors for each sample.\n",
        "        gap (float): Separation gap (Δ). If the absolute expectation exceeds\n",
        "            this, the sample is labeled ±1 based on the sign.\n",
        "        O (np.ndarray): Observable used for label determination.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Labels for each sample. Values will be -1, 0, or +1, where\n",
        "        0 indicates an expectation value within the gap zone (not exceeding ±gap).\n",
        "    \"\"\"\n",
        "    psi_dag = np.transpose(psi.conj(), (0, 2, 1))\n",
        "    exp_val = np.real(psi_dag @ mat_o @ psi).flatten()\n",
        "    labels = (np.abs(exp_val) > gap) * (np.sign(exp_val))\n",
        "    return labels\n",
        "\n",
        "\n",
        "def _measure(psi, eig):\n",
        "    \"\"\"\n",
        "    Compute labels by simulating a measurement of the observable on each state.\n",
        "\n",
        "    The eigen-decomposition of O is used as the measurement basis. Each state\n",
        "    is projected onto one of the eigenvectors, and labels are set to the\n",
        "    corresponding eigenvalue.\n",
        "\n",
        "    Args:\n",
        "        psi (np.ndarray): Array of shape `(num_samples, dim, 1)` containing\n",
        "            the statevectors for each sample.\n",
        "        eig (np.ndarray): Eigenvalues of Observable to be 'measured'\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Labels for each sample, set to one of the eigenvalues\n",
        "        of the observable O.\n",
        "    \"\"\"\n",
        "    eigenvalues, eigenvectors = eig\n",
        "    eigshape = eigenvectors.shape\n",
        "    new_psi = eigenvectors.T.conj().reshape((1, eigshape[1], eigshape[0])) @ psi\n",
        "\n",
        "    probab = np.abs(new_psi) ** 2\n",
        "    toss = algorithm_globals.random.random((psi.shape[0], 1))\n",
        "    cum_probab = np.cumsum(probab, axis=1).reshape(psi.shape[0], -1)\n",
        "    collapsed = (cum_probab >= toss).argmax(axis=-1, keepdims=True)\n",
        "    labels = eigenvalues[collapsed.flatten()]\n",
        "\n",
        "    return np.sign(labels)\n",
        "\n",
        "\n",
        "def _grid_sampling(n, n_samples, z_diags, zz_diags, psi_0, h_n, lab_fn):\n",
        "    \"\"\"\n",
        "    Generate feature vectors from a uniform grid (only supported for `n <= 3`)\n",
        "    and assign labels using the specified labeling function.\n",
        "\n",
        "    Args:\n",
        "        n (int): Number of qubits (dimension).\n",
        "        n_samples (int): Number of samples needed per class.\n",
        "        z_diags (np.ndarray): Array of single-qubit Z diagonal elements.\n",
        "        zz_diags (dict): Dictionary of ZZ-diagonal elements keyed by qubit pairs.\n",
        "        psi_0 (np.ndarray): Initial state vector.\n",
        "        h_n (np.ndarray): n-qubit Hadamard matrix.\n",
        "        lab_fn (Callable): Labeling function (either expectation-based or\n",
        "            measurement-based).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]:\n",
        "            Two arrays of shape `(n_samples, n)`, each containing the sampled\n",
        "            feature vectors belonging to class A and class B, respectively.\n",
        "            This code is incomplete and references variables not defined above,\n",
        "            so the returned arrays are empty placeholders by default.\n",
        "    \"\"\"\n",
        "\n",
        "    count = 1\n",
        "    if n == 1:\n",
        "        count = 5000\n",
        "    elif n == 2:\n",
        "        count = 100\n",
        "    elif n == 3:\n",
        "        count = 20\n",
        "\n",
        "    xvals = np.linspace(0, 2 * np.pi, count, endpoint=False)\n",
        "    grid_labels = []\n",
        "\n",
        "    # Loop through uniform grid\n",
        "    for x in it.product(*[xvals] * n):\n",
        "        x_arr = np.array(x)\n",
        "        pre_exp = 0\n",
        "        for i in range(n):\n",
        "            pre_exp += x_arr[i] * z_diags[i]\n",
        "        for i, j in zz_diags.keys():\n",
        "            pre_exp += ((np.pi - x_arr[i]) * (np.pi - x_arr[j])) * zz_diags[(i, j)]\n",
        "\n",
        "        uphi = np.diag(np.exp(1j * pre_exp.flatten()))\n",
        "        psi = uphi @ h_n @ uphi @ psi_0\n",
        "        label = lab_fn(psi.reshape((1, -1, 1)))\n",
        "\n",
        "        grid_labels.append(label)\n",
        "\n",
        "    grid_labels = np.array(grid_labels).reshape(*[count] * n)\n",
        "\n",
        "    count = grid_labels.shape[0]\n",
        "    a_features, b_features = [], []\n",
        "\n",
        "    while len(a_features) < n_samples:\n",
        "        draws = tuple(algorithm_globals.random.choice(count) for _ in range(n))\n",
        "        if grid_labels[draws] == 1:\n",
        "            a_features.append([xvals[d] for d in draws])\n",
        "\n",
        "    while len(b_features) < n_samples:\n",
        "        draws = tuple(algorithm_globals.random.choice(count) for _ in range(n))\n",
        "        if grid_labels[draws] == -1:\n",
        "            b_features.append([xvals[d] for d in draws])\n",
        "\n",
        "    return np.array(a_features), np.array(b_features)"
      ],
      "metadata": {
        "id": "29HyrBRYOOtc"
      },
      "id": "29HyrBRYOOtc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is part of a Qiskit project.\n",
        "#\n",
        "# (C) Copyright IBM 2020, 2025.\n",
        "#\n",
        "# This code is licensed under the Apache License, Version 2.0. You may\n",
        "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
        "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
        "#\n",
        "# Any modifications or derivative works of this code must retain this\n",
        "# copyright notice, and modified files need to carry a notice indicating\n",
        "# that they have been altered from the originals.\n",
        "\n",
        "\"\"\" Test Ad Hoc Data \"\"\"\n",
        "\n",
        "from test import QiskitMachineLearningTestCase\n",
        "\n",
        "import unittest\n",
        "import json\n",
        "import numpy as np\n",
        "from ddt import ddt, unpack, idata\n",
        "\n",
        "from qiskit_machine_learning.utils import algorithm_globals\n",
        "from qiskit_machine_learning.datasets import ad_hoc_data\n",
        "\n",
        "\n",
        "@ddt\n",
        "class TestAdHocData(QiskitMachineLearningTestCase):\n",
        "    \"\"\"Ad Hoc Data tests.\"\"\"\n",
        "\n",
        "    @idata(\n",
        "        ([2], [3]),\n",
        "    )\n",
        "    @unpack\n",
        "    def test_ad_hoc_data(self, num_features):\n",
        "        \"\"\"Ad Hoc Data test.\"\"\"\n",
        "        training_features, training_labels, _, test_labels = ad_hoc_data(\n",
        "            training_size=20,\n",
        "            test_size=10,\n",
        "            n=num_features,\n",
        "            gap=0.3,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "        )\n",
        "        np.testing.assert_array_equal(training_features.shape, (40, num_features))\n",
        "        np.testing.assert_array_equal(training_labels.shape, (40,))\n",
        "        np.testing.assert_array_almost_equal(test_labels, np.array([0] * 10 + [1] * 10))\n",
        "\n",
        "        # Now one_hot=True\n",
        "        _, _, _, test_labels_oh = ad_hoc_data(\n",
        "            training_size=20,\n",
        "            test_size=10,\n",
        "            n=num_features,\n",
        "            gap=0.3,\n",
        "            plot_data=False,\n",
        "            one_hot=True,\n",
        "        )\n",
        "        np.testing.assert_array_equal(test_labels_oh.shape, (20, 2))\n",
        "        np.testing.assert_array_equal(test_labels_oh, np.array([[1, 0]] * 10 + [[0, 1]] * 10))\n",
        "\n",
        "    def test_ref_data(self):\n",
        "        \"\"\"Tests ad hoc against known reference data\"\"\"\n",
        "        input_file = self.get_resource_path(\"ad_hoc_ref.json\", \"datasets\")\n",
        "        with open(input_file, encoding=\"utf8\") as file:\n",
        "            ref_data = json.load(file)\n",
        "\n",
        "        for seed in ref_data:\n",
        "            algorithm_globals.random_seed = int(seed)\n",
        "            (\n",
        "                training_features,\n",
        "                training_labels,\n",
        "                test_features,\n",
        "                test_labels,\n",
        "            ) = ad_hoc_data(\n",
        "                training_size=20,\n",
        "                test_size=5,\n",
        "                n=2,\n",
        "                gap=0.3,\n",
        "                plot_data=False,\n",
        "                one_hot=False,\n",
        "            )\n",
        "            with self.subTest(\"Test training_features\"):\n",
        "                np.testing.assert_almost_equal(\n",
        "                    ref_data[seed][\"training_features\"],\n",
        "                    training_features,\n",
        "                )\n",
        "            with self.subTest(\"Test training_labels\"):\n",
        "                np.testing.assert_almost_equal(\n",
        "                    ref_data[seed][\"training_labels\"],\n",
        "                    training_labels,\n",
        "                )\n",
        "            with self.subTest(\"Test test_features\"):\n",
        "                np.testing.assert_almost_equal(\n",
        "                    ref_data[seed][\"test_features\"],\n",
        "                    test_features,\n",
        "                )\n",
        "            with self.subTest(\"Test test_labels\"):\n",
        "                np.testing.assert_almost_equal(\n",
        "                    ref_data[seed][\"test_labels\"],\n",
        "                    test_labels,\n",
        "                )\n",
        "\n",
        "    def test_entanglement_linear(self):\n",
        "        \"\"\"Test linear entanglement.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            training_labels,\n",
        "            test_features,\n",
        "            test_labels,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            entanglement=\"linear\",\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (20, 2))\n",
        "        self.assertEqual(training_labels.shape, (20,))\n",
        "        self.assertEqual(test_features.shape, (10, 2))\n",
        "        self.assertEqual(test_labels.shape, (10,))\n",
        "\n",
        "    def test_entanglement_circular(self):\n",
        "        \"\"\"Test circular entanglement.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            training_labels,\n",
        "            test_features,\n",
        "            test_labels,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            entanglement=\"circular\",\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (20, 2))\n",
        "        self.assertEqual(training_labels.shape, (20,))\n",
        "        self.assertEqual(test_features.shape, (10, 2))\n",
        "        self.assertEqual(test_labels.shape, (10,))\n",
        "\n",
        "    def test_entanglement_full(self):\n",
        "        \"\"\"Test full entanglement.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            training_labels,\n",
        "            test_features,\n",
        "            test_labels,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            entanglement=\"full\",\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (20, 2))\n",
        "        self.assertEqual(training_labels.shape, (20,))\n",
        "        self.assertEqual(test_features.shape, (10, 2))\n",
        "        self.assertEqual(test_labels.shape, (10,))\n",
        "\n",
        "    def test_sampling_grid(self):\n",
        "        \"\"\"Test grid sampling method.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            training_labels,\n",
        "            test_features,\n",
        "            test_labels,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            sampling_method=\"grid\",\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (20, 2))\n",
        "        self.assertEqual(training_labels.shape, (20,))\n",
        "        self.assertEqual(test_features.shape, (10, 2))\n",
        "        self.assertEqual(test_labels.shape, (10,))\n",
        "\n",
        "    def test_sampling_sobol(self):\n",
        "        \"\"\"Test Sobol sampling method.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            training_labels,\n",
        "            test_features,\n",
        "            test_labels,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            sampling_method=\"sobol\",\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (20, 2))\n",
        "        self.assertEqual(training_labels.shape, (20,))\n",
        "        self.assertEqual(test_features.shape, (10, 2))\n",
        "        self.assertEqual(test_labels.shape, (10,))\n",
        "\n",
        "    def test_sampling_hypercube(self):\n",
        "        \"\"\"Test hypercube sampling with divisions parameter.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            training_labels,\n",
        "            test_features,\n",
        "            test_labels,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            sampling_method=\"hypercube\",\n",
        "            divisions=10,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (20, 2))\n",
        "        self.assertEqual(training_labels.shape, (20,))\n",
        "        self.assertEqual(test_features.shape, (10, 2))\n",
        "        self.assertEqual(test_labels.shape, (10,))\n",
        "\n",
        "    def test_labelling_expectation(self):\n",
        "        \"\"\"Test expectation labelling method.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            training_labels,\n",
        "            test_features,\n",
        "            test_labels,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            labelling_method=\"expectation\",\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (20, 2))\n",
        "        self.assertEqual(training_labels.shape, (20,))\n",
        "        self.assertEqual(test_features.shape, (10, 2))\n",
        "        self.assertEqual(test_labels.shape, (10,))\n",
        "\n",
        "    def test_labelling_measurement(self):\n",
        "        \"\"\"Test measurement labelling method.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            training_labels,\n",
        "            test_features,\n",
        "            test_labels,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            labelling_method=\"measurement\",\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (20, 2))\n",
        "        self.assertEqual(training_labels.shape, (20,))\n",
        "        self.assertEqual(test_features.shape, (10, 2))\n",
        "        self.assertEqual(test_labels.shape, (10,))\n",
        "\n",
        "    def test_custom_class_labels(self):\n",
        "        \"\"\"Test custom class labels.\"\"\"\n",
        "        custom_labels = [\"Class1\", \"Class2\"]\n",
        "        (\n",
        "            _,\n",
        "            training_labels,\n",
        "            _,\n",
        "            _,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            class_labels=custom_labels,\n",
        "        )\n",
        "\n",
        "        unique_labels = np.unique(training_labels)\n",
        "        self.assertEqual(len(unique_labels), 2)\n",
        "        for label in custom_labels:\n",
        "            self.assertIn(label, unique_labels)\n",
        "\n",
        "        # Test with one_hot=True\n",
        "        (\n",
        "            _,\n",
        "            training_labels_onehot,\n",
        "            _,\n",
        "            test_labels_onehot,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            plot_data=False,\n",
        "            one_hot=True,\n",
        "            class_labels=custom_labels,\n",
        "        )\n",
        "\n",
        "        self.assertEqual(training_labels_onehot.shape, (20, 2))\n",
        "        self.assertEqual(test_labels_onehot.shape, (10, 2))\n",
        "\n",
        "    def test_include_sample_total(self):\n",
        "        \"\"\"Test include_sample_total parameter returns 5-tuple.\"\"\"\n",
        "        result = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            include_sample_total=True,\n",
        "        )\n",
        "        self.assertEqual(len(result), 5)\n",
        "        np.testing.assert_array_equal(result[4], np.array([30]))\n",
        "\n",
        "    def test_higher_qubits(self):\n",
        "        \"\"\"Test with dimensions higher than 3 (n=4).\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            _,\n",
        "            test_features,\n",
        "            _,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=5,\n",
        "            test_size=3,\n",
        "            n=4,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            sampling_method=\"sobol\",\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (10, 4))\n",
        "        self.assertEqual(test_features.shape, (6, 4))\n",
        "\n",
        "    def test_error_cases(self):\n",
        "        \"\"\"Test error cases in the new implementation.\"\"\"\n",
        "\n",
        "        # Test negative training_size\n",
        "        with self.assertRaises(ValueError):\n",
        "            ad_hoc_data(training_size=-1, test_size=5, n=2)\n",
        "\n",
        "        # Test negative test_size\n",
        "        with self.assertRaises(ValueError):\n",
        "            ad_hoc_data(training_size=5, test_size=-1, n=2)\n",
        "\n",
        "        # Test invalid n\n",
        "        with self.assertRaises(ValueError):\n",
        "            ad_hoc_data(training_size=5, test_size=5, n=0)\n",
        "\n",
        "        # Test negative gap with expectation labelling\n",
        "        with self.assertRaises(ValueError):\n",
        "            ad_hoc_data(\n",
        "                training_size=5,\n",
        "                test_size=5,\n",
        "                n=2,\n",
        "                gap=-1,\n",
        "                labelling_method=\"expectation\",\n",
        "            )\n",
        "\n",
        "        # Test invalid entanglement\n",
        "        with self.assertRaises(ValueError):\n",
        "            ad_hoc_data(\n",
        "                training_size=5,\n",
        "                test_size=5,\n",
        "                n=2,\n",
        "                entanglement=\"invalid\",\n",
        "            )\n",
        "\n",
        "        # Test invalid sampling method\n",
        "        with self.assertRaises(ValueError):\n",
        "            ad_hoc_data(\n",
        "                training_size=5,\n",
        "                test_size=5,\n",
        "                n=2,\n",
        "                sampling_method=\"invalid\",\n",
        "            )\n",
        "\n",
        "        # Test hypercube without divisions\n",
        "        with self.assertRaises(ValueError):\n",
        "            ad_hoc_data(\n",
        "                training_size=5,\n",
        "                test_size=5,\n",
        "                n=2,\n",
        "                sampling_method=\"hypercube\",\n",
        "            )\n",
        "\n",
        "        # Test invalid labelling method\n",
        "        with self.assertRaises(ValueError):\n",
        "            ad_hoc_data(\n",
        "                training_size=5,\n",
        "                test_size=5,\n",
        "                n=2,\n",
        "                labelling_method=\"invalid\",\n",
        "            )\n",
        "\n",
        "        # Test grid sampling with n > 3\n",
        "        with self.assertRaises(ValueError):\n",
        "            ad_hoc_data(\n",
        "                training_size=5,\n",
        "                test_size=5,\n",
        "                n=4,\n",
        "                sampling_method=\"grid\",\n",
        "            )\n",
        "\n",
        "    def test_hypercube_sampling_linear_entanglement(self):\n",
        "        \"\"\"Test hypercube sampling and linear entanglement.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            _,\n",
        "            test_features,\n",
        "            _,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            sampling_method=\"hypercube\",\n",
        "            divisions=12,\n",
        "            entanglement=\"linear\",\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (20, 2))\n",
        "        self.assertEqual(test_features.shape, (10, 2))\n",
        "\n",
        "    def test_custom_labels_circular_entanglement(self):\n",
        "        \"\"\"Test custom labels with circular entanglement.\"\"\"\n",
        "        custom_labels = [\"Yes\", \"No\"]\n",
        "        (\n",
        "            training_features,\n",
        "            training_labels,\n",
        "            test_features,\n",
        "            _,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=8,\n",
        "            test_size=4,\n",
        "            n=3,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            entanglement=\"circular\",\n",
        "            class_labels=custom_labels,\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (16, 3))\n",
        "        self.assertEqual(test_features.shape, (8, 3))\n",
        "        unique_labels = np.unique(training_labels)\n",
        "        self.assertIn(\"Yes\", unique_labels)\n",
        "        self.assertIn(\"No\", unique_labels)\n",
        "\n",
        "    def test_measurement_sobol_sampling(self):\n",
        "        \"\"\"Test custom labels with circular entanglement.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            _,\n",
        "            test_features,\n",
        "            _,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=8,\n",
        "            test_size=4,\n",
        "            n=3,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            labelling_method=\"measurement\",\n",
        "            sampling_method=\"sobol\",\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (16, 3))\n",
        "        self.assertEqual(test_features.shape, (8, 3))\n",
        "\n",
        "    def test_expectation_labelling_with_gap(self):\n",
        "        \"\"\"Test expectation labelling with a non-zero gap.\"\"\"\n",
        "        (\n",
        "            training_features,\n",
        "            _,\n",
        "            test_features,\n",
        "            _,\n",
        "        ) = ad_hoc_data(\n",
        "            training_size=10,\n",
        "            test_size=5,\n",
        "            n=2,\n",
        "            gap=0.5,\n",
        "            plot_data=False,\n",
        "            one_hot=False,\n",
        "            labelling_method=\"expectation\",\n",
        "        )\n",
        "        self.assertEqual(training_features.shape, (20, 2))\n",
        "        self.assertEqual(test_features.shape, (10, 2))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main()"
      ],
      "metadata": {
        "id": "OetJjGTzOr6v"
      },
      "id": "OetJjGTzOr6v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is part of a Qiskit project.\n",
        "#\n",
        "# (C) Copyright IBM 2023, 2024.\n",
        "#\n",
        "# This code is licensed under the Apache License, Version 2.0. You may\n",
        "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
        "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
        "#\n",
        "# Any modifications or derivative works of this code must retain this\n",
        "# copyright notice, and modified files need to carry a notice indicating\n",
        "# that they have been altered from the originals.\n",
        "\n",
        "\"\"\"The QNN circuit.\"\"\"\n",
        "from __future__ import annotations\n",
        "from typing import List\n",
        "\n",
        "from qiskit.circuit import QuantumRegister, QuantumCircuit\n",
        "from qiskit.circuit.parametertable import ParameterView\n",
        "from qiskit.circuit.library import BlueprintCircuit\n",
        "\n",
        "from qiskit_machine_learning import QiskitMachineLearningError\n",
        "\n",
        "from ...utils import derive_num_qubits_feature_map_ansatz\n",
        "\n",
        "\n",
        "class QNNCircuit(BlueprintCircuit):\n",
        "    \"\"\"\n",
        "    The QNN circuit is a blueprint circuit that wraps feature map and ansatz circuits.\n",
        "    It can be used to simplify the composition of these two.\n",
        "\n",
        "    If only the number of qubits is provided the :class:`~qiskit.circuit.library.RealAmplitudes`\n",
        "    ansatz and the :class:`~qiskit.circuit.library.ZZFeatureMap` feature map are used. If the\n",
        "    number of qubits is 1 the :class:`~qiskit.circuit.library.ZFeatureMap` is used. If only a\n",
        "    feature map is provided, the :class:`~qiskit.circuit.library.RealAmplitudes` ansatz with the\n",
        "    corresponding number of qubits is used. If only an ansatz is provided the\n",
        "    :class:`~qiskit.circuit.library.ZZFeatureMap` with the corresponding number of qubits is used.\n",
        "\n",
        "    At least one parameter has to be provided. If a feature map and an ansatz is provided, the\n",
        "    number of qubits must be the same.\n",
        "\n",
        "    In case number of qubits is provided along with either a feature map, an ansatz or both, a\n",
        "    potential mismatch between the three inputs with respect to the number of qubits is resolved by\n",
        "    constructing the :class:`~qiskit_machine_learning.circuit.library.QNNCircuit` with the given\n",
        "    number of qubits. If one of the :class:`~qiskit_machine_learning.circuit.library.QNNCircuit`\n",
        "    properties is set after the class construction, the circuit is adjusted  to incorporate the\n",
        "    changes. This means, a new valid configuration that considers the latest property update will be\n",
        "    derived. This ensures that the classes properties are consistent at all times.\n",
        "\n",
        "    Example:\n",
        "\n",
        "    .. code-block:: python\n",
        "\n",
        "        from qiskit_machine_learning.circuit.library import QNNCircuit\n",
        "        qnn_qc = QNNCircuit(2)\n",
        "        print(qnn_qc)\n",
        "        # prints:\n",
        "        #      ┌──────────────────────────┐»\n",
        "        # q_0: ┤0                         ├»\n",
        "        #      │  ZZFeatureMap(x[0],x[1]) │»\n",
        "        # q_1: ┤1                         ├»\n",
        "        #      └──────────────────────────┘»\n",
        "        # «     ┌──────────────────────────────────────────────────────────┐\n",
        "        # «q_0: ┤0                                                         ├\n",
        "        # «     │  RealAmplitudes(θ[0],θ[1],θ[2],θ[3],θ[4],θ[5],θ[6],θ[7]) │\n",
        "        # «q_1: ┤1                                                         ├\n",
        "        # «     └──────────────────────────────────────────────────────────┘\n",
        "\n",
        "        print(qnn_qc.num_qubits)\n",
        "        # prints: 2\n",
        "\n",
        "        print(qnn_qc.input_parameters)\n",
        "        # prints: ParameterView([ParameterVectorElement(x[0]), ParameterVectorElement(x[1])])\n",
        "\n",
        "        print(qnn_qc.weight_parameters)\n",
        "        # prints: ParameterView([ParameterVectorElement(θ[0]), ParameterVectorElement(θ[1]),\n",
        "        #         ParameterVectorElement(θ[2]), ParameterVectorElement(θ[3]),\n",
        "        #         ParameterVectorElement(θ[4]), ParameterVectorElement(θ[5]),\n",
        "        #         ParameterVectorElement(θ[6]), ParameterVectorElement(θ[7])])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_qubits: int | None = None,\n",
        "        feature_map: QuantumCircuit | None = None,\n",
        "        ansatz: QuantumCircuit | None = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Although all parameters default to None at least one parameter must be provided, to determine\n",
        "        the number of qubits from it, when the instance is created.\n",
        "\n",
        "        If more than one parameter is passed:\n",
        "\n",
        "        1) If num_qubits is provided the feature map and/or ansatz supplied will be overridden to\n",
        "        circuits with num_qubits, as long as the respective circuit supports updating its number of\n",
        "        qubits.\n",
        "\n",
        "        2) If num_qubits is not provided the feature_map and ansatz must be set to the same number\n",
        "        of qubits.\n",
        "\n",
        "        Args:\n",
        "            num_qubits:  Number of qubits, a positive integer. Optional if feature_map or ansatz is\n",
        "                         provided, otherwise required. If not provided num_qubits defaults from the\n",
        "                         sizes of feature_map and ansatz.\n",
        "            feature_map: A feature map. Optional if num_qubits or ansatz is provided, otherwise\n",
        "                         required. If not provided defaults to\n",
        "                         :class:`~qiskit.circuit.library.ZZFeatureMap` or\n",
        "                         :class:`~qiskit.circuit.library.ZFeatureMap` if num_qubits is determined\n",
        "                         to be 1.\n",
        "            ansatz:      An ansatz. Optional if num_qubits or feature_map is provided, otherwise\n",
        "                         required. If not provided defaults to\n",
        "                         :class:`~qiskit.circuit.library.RealAmplitudes`.\n",
        "\n",
        "        Returns:\n",
        "            The composed feature map and ansatz circuit.\n",
        "\n",
        "        Raises:\n",
        "            QiskitMachineLearningError: If a valid number of qubits cannot be derived from the \\\n",
        "            provided input arguments.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self._feature_map = feature_map\n",
        "        self._ansatz = ansatz\n",
        "        # Check if circuit is constructed with valid configuration and set properties accordingly.\n",
        "        self.num_qubits, self._feature_map, self._ansatz = derive_num_qubits_feature_map_ansatz(\n",
        "            num_qubits, feature_map, ansatz\n",
        "        )\n",
        "\n",
        "    def _build(self):\n",
        "        super()._build()\n",
        "        self.compose(self.feature_map, inplace=True)\n",
        "        self.compose(self.ansatz, inplace=True)\n",
        "\n",
        "    def _check_configuration(self, raise_on_failure=True):\n",
        "        try:\n",
        "            self.num_qubits, self.feature_map, self.ansatz = derive_num_qubits_feature_map_ansatz(\n",
        "                self.num_qubits, self.feature_map, self.ansatz\n",
        "            )\n",
        "        except QiskitMachineLearningError as qml_ex:\n",
        "            if raise_on_failure:\n",
        "                raise qml_ex\n",
        "\n",
        "    @property\n",
        "    def num_qubits(self) -> int:\n",
        "        \"\"\"Returns the number of qubits in this circuit.\n",
        "\n",
        "        Returns:\n",
        "            The number of qubits.\n",
        "        \"\"\"\n",
        "        return super().num_qubits\n",
        "\n",
        "    @num_qubits.setter\n",
        "    def num_qubits(self, num_qubits: int) -> None:\n",
        "        \"\"\"Set the number of qubits. If num_qubits is set\n",
        "        the feature map and ansatz are adjusted to circuits with num_qubits qubits.\n",
        "\n",
        "        Args:\n",
        "            num_qubits:  The number of qubits, a positive integer.\n",
        "        \"\"\"\n",
        "        if self.num_qubits != num_qubits:\n",
        "            # invalidate the circuit\n",
        "            self._invalidate()\n",
        "            self.qregs: List[QuantumRegister] = []\n",
        "            if num_qubits is not None and num_qubits > 0:\n",
        "                self.qregs = [QuantumRegister(num_qubits, name=\"q\")]\n",
        "                (\n",
        "                    self.num_qubits,\n",
        "                    self._feature_map,\n",
        "                    self._ansatz,\n",
        "                ) = derive_num_qubits_feature_map_ansatz(\n",
        "                    num_qubits, self._feature_map, self._ansatz\n",
        "                )\n",
        "\n",
        "    @property\n",
        "    def feature_map(self) -> QuantumCircuit:\n",
        "        \"\"\"Returns feature_map.\n",
        "\n",
        "        Returns:\n",
        "            The feature map.\n",
        "        \"\"\"\n",
        "        return self._feature_map\n",
        "\n",
        "    @feature_map.setter\n",
        "    def feature_map(self, feature_map: QuantumCircuit) -> None:\n",
        "        \"\"\"Set the feature map. If the feature map is updated the ``QNNCircuit`` is adjusted\n",
        "        according to the feature map being passed. This includes:\n",
        "        1) The num_qubits is adjusted to the feature map number of qubits.\n",
        "        2) The ansatz is adjusted to a circuit with the feature_map number of qubits.\n",
        "\n",
        "        Args:\n",
        "            feature_map: The feature map.\n",
        "        \"\"\"\n",
        "        if self.feature_map != feature_map:\n",
        "            # invalidate the circuit\n",
        "            self._invalidate()\n",
        "            self.num_qubits = feature_map.num_qubits\n",
        "            self.num_qubits, self._feature_map, self._ansatz = derive_num_qubits_feature_map_ansatz(\n",
        "                self.num_qubits, feature_map, self.ansatz\n",
        "            )\n",
        "\n",
        "    @property\n",
        "    def ansatz(self) -> QuantumCircuit:\n",
        "        \"\"\"Returns ansatz.\n",
        "\n",
        "        Returns:\n",
        "            The ansatz.\n",
        "        \"\"\"\n",
        "        return self._ansatz\n",
        "\n",
        "    @ansatz.setter\n",
        "    def ansatz(self, ansatz: QuantumCircuit) -> None:\n",
        "        \"\"\"Set the ansatz. If the ansatz is updated the ``QNNCircuit`` is adapted\n",
        "        according to the ansatz being passed. This includes:\n",
        "        1) The num_qubits is adjusted to the ansatz number of qubits.\n",
        "        2) The feature_map is adjusted to a circuit with the ansatz number of qubits.\n",
        "\n",
        "        Args:\n",
        "            ansatz: The ansatz.\n",
        "        \"\"\"\n",
        "        if self.ansatz != ansatz:\n",
        "            # invalidate the circuit\n",
        "            self._invalidate()\n",
        "            self.num_qubits = ansatz.num_qubits\n",
        "            self.num_qubits, self._feature_map, self._ansatz = derive_num_qubits_feature_map_ansatz(\n",
        "                self.num_qubits, self.feature_map, ansatz\n",
        "            )\n",
        "\n",
        "    @property\n",
        "    def input_parameters(self) -> ParameterView:\n",
        "        \"\"\"Returns the parameters of the feature map.\n",
        "\n",
        "        Returns:\n",
        "            The parameters of the feature map.\n",
        "        \"\"\"\n",
        "        return self._feature_map.parameters\n",
        "\n",
        "    @property\n",
        "    def num_input_parameters(self) -> int:\n",
        "        \"\"\"Returns the number of input parameters in the circuit.\n",
        "\n",
        "        Returns:\n",
        "            The number of input parameters.\n",
        "        \"\"\"\n",
        "        return len(self._feature_map.parameters)\n",
        "\n",
        "    @property\n",
        "    def weight_parameters(self) -> ParameterView:\n",
        "        \"\"\"Returns the parameters of the ansatz. These corresponding to the trainable weights.\n",
        "\n",
        "        Returns:\n",
        "            The parameters of the ansatz.\n",
        "        \"\"\"\n",
        "        return self._ansatz.parameters\n",
        "\n",
        "    @property\n",
        "    def num_weight_parameters(self) -> int:\n",
        "        \"\"\"Returns the number of weights in the circuit.\n",
        "\n",
        "        Returns:\n",
        "            The number of weights.\n",
        "        \"\"\"\n",
        "        return len(self._ansatz.parameters)"
      ],
      "metadata": {
        "id": "3z0eITDKAMVm"
      },
      "id": "3z0eITDKAMVm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}